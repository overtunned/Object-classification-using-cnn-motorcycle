{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Predict Image Category from 256 Categories**","metadata":{"_uuid":"0ce14b3f1765b91da6081d43808a228e8c92356f"}},{"cell_type":"markdown","source":"**Caltech 256 Image Dataset**\n* Over 30,000 images in 256 object categories\n","metadata":{"_uuid":"0857589a5c37704a1ef44a8fb1843b1bc00a7d46"}},{"cell_type":"markdown","source":"*Step 1: Import Python Packages*","metadata":{"_uuid":"88e07c64f2a7372dd38f0f27066eba35efd344ba"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom os import listdir\nfrom glob import glob\nimport itertools\nimport fnmatch\nimport random\nfrom PIL import Image\nimport zlib\nimport itertools\nimport csv\nfrom tqdm import tqdm\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport cv2\nimport skimage\nfrom skimage import transform\nfrom skimage.transform import resize\nimport scipy\nfrom scipy.misc import imresize, imread\nfrom scipy import misc\nimport keras\nfrom keras import backend as K\nfrom keras import models, layers, optimizers\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.models import Model, Sequential, model_from_json\nfrom keras.layers import Dense, Dropout, Input, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D, Lambda, AveragePooling2D\nfrom keras.utils import np_utils\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\nimport sklearn\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, learning_curve, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\nfrom sklearn.utils import class_weight\n%matplotlib inline","metadata":{"_uuid":"e5a195cbea78112f2b0e119668f942371aefacce","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Step 2: Define Helper Functions*","metadata":{"_uuid":"9c851baf2af1195528c8342f1f638e401dc5a288"}},{"cell_type":"code","source":"# Helper Functions for Learning Curve and Confusion Matrix\n\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nclass MetricsCheckpoint(Callback):\n    \"\"\"Callback that saves metrics after each epoch\"\"\"\n    def __init__(self, savepath):\n        super(MetricsCheckpoint, self).__init__()\n        self.savepath = savepath\n        self.history = {}\n    def on_epoch_end(self, epoch, logs=None):\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        np.save(self.savepath, self.history)\n\ndef plotKerasLearningCurve():\n    plt.figure(figsize=(10,5))\n    metrics = np.load('logs.npy')[()]\n    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n        l = np.array(metrics[k])\n        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n        y = l[x]\n        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n    plt.legend(loc=4)\n    plt.axis([0, None, None, None]);\n    plt.grid()\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Accuracy')\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (20,20))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\ndef plot_learning_curve(history):\n    plt.figure(figsize=(8,8))\n    plt.subplot(1,2,1)\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('./accuracy_curve.png')\n    plt.subplot(1,2,2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('./loss_curve.png')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"59e3fb96a39a236fc34cb2c7476f36d029af2da6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Step 3: Load Data*","metadata":{"_uuid":"0d7007d4a087fca285d53fcf154f4c51b9934332"}},{"cell_type":"markdown","source":"We will only load 14 images from each category because of the computational constraints of the Kaggle Kernel.  When we have more powerful kernels I will increase this number.","metadata":{"_uuid":"12477f9f6089c586e58fa09e2e5c6a4747f4a658"}},{"cell_type":"code","source":"# adapted from https://github.com/aliasvishnu/Keras-VGG16-TransferLearning/blob/master/Caltech%20256%20-%20Dark%20Knowledge.ipynb\n# I like this loading function because you can control the number of samples for each category.  \n\ndef loadBatchImages(path,nSamples,nVal):\n    catList = listdir(path)\n    loadedImagesTrain = []\n    loadedLabelsTrain = []\n    loadedImagesVal = []\n    loadedLabelsVal = []\n    for cat in catList[0:256]:\n        deepPath = path+cat+\"/\"\n        imageList = listdir(deepPath)\n        indx = 0\n        for images in imageList[0:nSamples + nVal]:                \n            img = load_img(deepPath + images)\n            img = img_to_array(img)\n            img = misc.imresize(img, (224,224))\n            if indx < nSamples:\n                loadedLabelsTrain.append(int(images[0:3])-1)\n                loadedImagesTrain.append(img)\n            else:\n                loadedLabelsVal.append(int(images[0:3])-1)\n                loadedImagesVal.append(img)\n            indx += 1\n    return loadedImagesTrain, np_utils.to_categorical(loadedLabelsTrain), loadedImagesVal, np_utils.to_categorical(loadedLabelsVal) \n\ndef shuffledSet(a, b):\n    assert np.shape(a)[0] == np.shape(b)[0]\n    p = np.random.permutation(np.shape(a)[0])\n    return (a[p], b[p])\n\npath = '../input/caltech256/256_objectcategories/256_ObjectCategories/'\nnSamples = 7 \nnVal = 7  \ndata, labels, dataVal, labelsVal = loadBatchImages(path,nSamples,nVal)\ndata = preprocess_input(np.float64(data))\ndataVal = preprocess_input(np.float64(dataVal))\ntrain = shuffledSet(np.asarray(data),labels)\nval = shuffledSet(np.asarray(dataVal),labelsVal)\nX_train = train[0]\ny_train = train[1]\nX_test = val[0]\ny_test = val[1]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Step 4: Explore Data*","metadata":{"_uuid":"6dfa173de115f3dfb882aab209387d9d09d8334b"}},{"cell_type":"markdown","source":"Category #1 of 256: Triceratops","metadata":{"_uuid":"4cac47bd880eb37dc3e0a55a60cd5fd1d18057f2"}},{"cell_type":"code","source":"multipleImages = glob('../input/caltech256/256_objectcategories/256_ObjectCategories/228.triceratops/**')\ndef plotThreeImages(images):\n    r = random.sample(images, 3)\n    plt.figure(figsize=(16,16))\n    plt.subplot(131)\n    plt.imshow(cv2.imread(r[0]))\n    plt.subplot(132)\n    plt.imshow(cv2.imread(r[1]))\n    plt.subplot(133)\n    plt.imshow(cv2.imread(r[2])); \nplotThreeImages(multipleImages)\nplotThreeImages(multipleImages)\nplotThreeImages(multipleImages)","metadata":{"_uuid":"8d09aa7633bfda7e8dda238370c1762bd1a56fcf","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multipleImages = glob('../input/caltech256/256_objectcategories/256_ObjectCategories/228.triceratops/**')\ndef plotImages(path,begin,end):\n    i_ = 0\n    plt.rcParams['figure.figsize'] = (15.0, 15.0)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    for l in multipleImages[begin:end]:\n        im = cv2.imread(l)\n        im = cv2.resize(im, (128, 128)) \n        plt.subplot(5, 5, i_+1) #.set_title(l)\n        plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n        i_ += 1\n    plt.show()\nplotImages(multipleImages,0,25)  \nplotImages(multipleImages,25,50)  ","metadata":{"_uuid":"beb09fc58b31576cc4fefd33c19a7ea5b56e8d75","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Category #2 of 256: Goose","metadata":{"_uuid":"7e42206894a61d983eea4135c24755e7ba824344"}},{"cell_type":"code","source":"multipleImages = glob('../input/caltech256/256_objectcategories/256_ObjectCategories/089.goose/**')\nplotThreeImages(multipleImages)\nplotThreeImages(multipleImages)\nplotThreeImages(multipleImages)","metadata":{"_uuid":"1efbccf111feb089fea87191f2ac100f37ecf1de","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multipleImages = glob('../input/caltech256/256_objectcategories/256_ObjectCategories/089.goose/**')\nplotImages(multipleImages,0,25)  \nplotImages(multipleImages,25,50)  ","metadata":{"_uuid":"3ab6a763aae92d8c9eb1be0e8bb0740548118d27","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Step 5: Evaluate ML Models*","metadata":{"_uuid":"3bb5d9e4835c1d68be005cd089ad7fa93f3a686c"}},{"cell_type":"markdown","source":"Pre-trained VGG16 model without top.","metadata":{"_uuid":"df961bfdc824d499bc3896b57673b19a48be7758"}},{"cell_type":"code","source":"class_weight1 = None\nweight_path1 = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\nweight_path2 = '../input/keras-pretrained-models/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\npretrained_model_1 = VGG16(weights = weight_path1, include_top=False, input_shape=(224, 224, 3))\npretrained_model_2 = InceptionV3(weights = weight_path2, include_top=False, input_shape=(224, 224, 3))\noptimizer1 = keras.optimizers.RMSprop(lr=0.0001)\n\ndef vggModelWithNoTop(xtrain,ytrain,xtest,ytest,pretrainedmodel,pretrainedweights,classweight,numclasses,numepochs,optimizer,labels):\n    base_model = pretrained_model_1 # Topless\n    # Add top layer\n    x = base_model.output\n    x = Conv2D(256, kernel_size = (3,3), padding = 'valid')(x)\n    x = Flatten()(x)\n    x = Dropout(0.75)(x)\n    predictions = Dense(numclasses, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    # Train top layer\n    for layer in base_model.layers:\n        layer.trainable = False\n    model.compile(loss='categorical_crossentropy', \n                  optimizer=optimizer, \n                  metrics=['accuracy'])\n    callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n    model.summary()\n    history = model.fit(xtrain,ytrain, epochs=numepochs, validation_data=(xtest,ytest), verbose=1, callbacks = [MetricsCheckpoint('logs')])\n    score = model.evaluate(xtest,ytest, verbose=0)\n    print('\\nAccuracy:', score[1], '\\n')\n    y_pred = model.predict(xtest)\n    #print('\\n', sklearn.metrics.classification_report(np.where(ytest > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels)), sep='') \n    Y_pred_classes = np.argmax(y_pred,axis = 1) \n    Y_true = np.argmax(ytest,axis = 1) \n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plotKerasLearningCurve()\n    plt.show()\n    plot_learning_curve(history)\n    plt.show()\n    #plot_confusion_matrix(confusion_mtx, classes = list(labels))\n    #plt.show()\n    return model\n","metadata":{"_uuid":"54ef14c800aaa26445731f93c7d8f85f00c1f834","_kg_hide-input":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vggModelWithNoTop(X_train, y_train, X_test, y_test,pretrained_model_1,weight_path1,class_weight1,257,70,optimizer1,labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pre-trained VGG16 model with top.","metadata":{"_uuid":"baa21770e2cc43a1232b740f5e276ff72a410151"}},{"cell_type":"code","source":"labels = os.listdir('../input/caltech256/256_objectcategories/256_ObjectCategories')\nweight_path3 = '../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\ndef vggModelWithTop(X,y,Xval,yval,numCategories,numEpochs, batchSize):\n    vgg_model = VGG16(weights=weight_path3, include_top=True)\n    vgg_out = vgg_model.layers[-1].output\n    out = Dense(numCategories, activation='softmax')( vgg_out )\n    model = Model( input=vgg_model.input, output=out)\n    model.layers[-2].activation=K.softmax\n    for layer in model.layers[0:-1]:\n        layer.trainable = False            \n    model.compile(loss= \"categorical_crossentropy\", optimizer=\"adagrad\", metrics=[\"accuracy\"])\n    callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n    model.summary()\n    history = model.fit(X, y, batch_size = batchSize, nb_epoch = numEpochs, validation_data = [Xval,yval], \n                           shuffle = True, callbacks = [MetricsCheckpoint('logs')])\n    score = model.evaluate(Xval,yval, verbose=0)\n    print('\\nAccuracy:', score[1], '\\n')\n    y_pred = model.predict(Xval)\n    print('\\n', sklearn.metrics.classification_report(np.where(yval > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels)), sep='') \n    Y_pred_classes = np.argmax(y_pred,axis = 1) \n    Y_true = np.argmax(yval,axis = 1) \n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plotKerasLearningCurve()\n    plt.show()\n    plot_learning_curve(history)\n    plt.show()\n    #plot_confusion_matrix(confusion_mtx, classes = list(labels))\n    #plt.show()\nvggModelWithTop(X_train,y_train,X_test,y_test, 257, 45, 16)","metadata":{"_uuid":"882dc2089498c4df73d5ae8dfe8b55213ea12ae0","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Step 6: Summarize Results*","metadata":{"_uuid":"19ed8c42045b561fb1b77265ad73aa71aecdc759","trusted":true}},{"cell_type":"markdown","source":"We were able to match images with image categories with an accuracy rate of approximately 50%.  Our best result was with a VGG16 pre-trained model (with top).  Our result of 50% accuracy is much better than random chance given 256 image categories but there is still a lot of room for improvement -- feel free to fork this kernel and make some changes!","metadata":{"_uuid":"0370859e01fd27fc20001590cdf64993e898ab9f"}}]}